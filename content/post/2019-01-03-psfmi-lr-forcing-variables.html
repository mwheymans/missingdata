---
title: Backward Logistic Regression after MI - forcing variables in model
author: Martijn Heymans
date: '2019-01-02'
slug: psfmi-lr-forcing-variables
categories: []
tags: ["psfmi", "force variables", "keep predictors", "interaction terms"]
thumbnailImagePosition: left
thumbnailImage: "/images/forcing.png"

---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>With the <a href="https://mwheymans.github.io/psfmi/">psfmi</a> package it is possible to force variables in the model during backward selection.
<!--more--></p>
<p>Be aware that backward selection may result in overfitted and optimistic prediction models, see <a href="http://annals.org/aim/fullarticle/2088542/transparent-reporting-multivariable-prediction-model-individual-prognosis-diagnosis-tripod-explanation">TRIPOD</a>. Backward selection should therefore be followed by internal validation of the model.</p>
<p>Forcing predictors in the model can be applied by using the <em>keep.predictors</em> option in
the psfmi_lr function. These variables can be continuous, dichotomous or
categorical variables. Also more than one variable can be forced in the model
during backward selection. Examples will be given below.</p>
<div id="examples" class="section level2">
<h2>Examples</h2>
<ul>
<li><a href="#pooling-with-bs-and-forcing-dichotomous-variable-in-the-model">Pooling with BS and forcing dichotomous variable in the model</a></li>
<li><a href="#pooling-with-bs-and-forcing-categorical-variable-in-the-model">Pooling with BS and forcing categorical variable in the model</a></li>
<li><a href="#pooling-with-bs-and-forcing-dichotomous-and-categorical-variable-in-the-model">Pooling with BS and forcing dichotomous and categorical variable in the model</a></li>
</ul>
<div id="pooling-with-bs-and-forcing-dichotomous-variable-in-the-model" class="section level3">
<h3>Pooling with BS and forcing dichotomous variable in the model</h3>
<p>Pooling Logistic regression models over 5 imputed datasets with backward selection
using a p-value of 0.05 and forcing the dichotomous predictor “Smoking” in the models
during backward selection with method D3 (Meng and Rubin likelihood ratio statistics method).</p>
<pre class="r"><code>library(psfmi)</code></pre>
<pre><code>## Registered S3 methods overwritten by &#39;car&#39;:
##   method                          from
##   influence.merMod                lme4
##   cooks.distance.influence.merMod lme4
##   dfbeta.influence.merMod         lme4
##   dfbetas.influence.merMod        lme4</code></pre>
<pre class="r"><code>pool_lr &lt;- psfmi_lr(data=lbpmilr, nimp=5, impvar=&quot;Impnr&quot;, Outcome=&quot;Chronic&quot;,
    predictors=c(&quot;Gender&quot;, &quot;Smoking&quot;, &quot;Function&quot;, &quot;JobControl&quot;,
    &quot;JobDemands&quot;, &quot;SocialSupport&quot;), keep.predictors = &quot;Smoking&quot;,
    p.crit = 0.05, method=&quot;D3&quot;, direction=&quot;BW&quot;)</code></pre>
<pre><code>## Warning: The `keep` argument of `group_split()` is deprecated as of dplyr 1.0.0.
## Please use the `.keep` argument instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre><code>## Removed at Step 1 is - JobDemands</code></pre>
<pre><code>## Removed at Step 2 is - JobControl</code></pre>
<pre><code>## Removed at Step 3 is - SocialSupport</code></pre>
<pre><code>## Removed at Step 4 is - Gender</code></pre>
<pre><code>## 
## Selection correctly terminated, 
## No more variables removed from the model</code></pre>
<pre class="r"><code>pool_lr$RR_Model</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>pool_lr$multiparm</code></pre>
<pre><code>## $`Step 1 - removal - JobDemands`
##                p-values D3  F-statistic
## Gender        0.3947458613  0.724373380
## Smoking       0.8317349667  0.045147955
## Function      0.0007899068 11.386844932
## JobControl    0.7343871650  0.115354428
## JobDemands    0.9519212712  0.003639672
## SocialSupport 0.4393657267  0.598319744
## 
## $`Step 2 - removal - JobControl`
##               p-values D3 F-statistic
## Gender        0.377527259  0.77873859
## Smoking       0.832083852  0.04495781
## Function      0.001008495 11.02012661
## JobControl    0.736740083  0.11324567
## SocialSupport 0.439547612  0.59781850
## 
## $`Step 3 - removal - SocialSupport`
##                p-values D3 F-statistic
## Gender        0.3229454514   0.9769937
## Smoking       0.8260364908   0.0483077
## Function      0.0007498005  11.4658858
## SocialSupport 0.4734125383   0.5143055
## 
## $`Step 4 - removal - Gender`
##          p-values D3 F-statistic
## Gender   0.294148237  1.10054585
## Smoking  0.843204307  0.03912415
## Function 0.000911838 11.10833407
## 
## $`Step 5 - removal - ended`
##           p-values D3 F-statistic
## Smoking  0.8523804814  0.03462715
## Function 0.0005132484 12.18345056</code></pre>
<p>Back to <a href="#examples">Examples</a></p>
</div>
<div id="pooling-with-bs-and-forcing-categorical-variable-in-the-model" class="section level3">
<h3>Pooling with BS and forcing categorical variable in the model</h3>
<p>Pooling Logistic regression models over 5 imputed datasets with backward selection
using a p-value of 0.05 and forcing the categorical predictor “Satisfaction” in the models
during backward selection with method D1.</p>
<pre class="r"><code>library(psfmi)
pool_lr &lt;- psfmi_lr(data=lbpmilr, nimp=5, impvar=&quot;Impnr&quot;, Outcome=&quot;Chronic&quot;,
    predictors=c(&quot;Gender&quot;, &quot;Smoking&quot;, &quot;Function&quot;, &quot;JobControl&quot;,
    &quot;JobDemands&quot;, &quot;SocialSupport&quot;), cat.predictors = &quot;Satisfaction&quot;, 
    keep.predictors = &quot;Satisfaction&quot;,
    p.crit = 0.05, method=&quot;D1&quot;, direction=&quot;BW&quot;)</code></pre>
<pre><code>## Removed at Step 1 is - Smoking</code></pre>
<pre><code>## Removed at Step 2 is - JobDemands</code></pre>
<pre><code>## Removed at Step 3 is - JobControl</code></pre>
<pre><code>## Removed at Step 4 is - SocialSupport</code></pre>
<pre><code>## Removed at Step 5 is - Gender</code></pre>
<pre><code>## 
## Selection correctly terminated, 
## No more variables removed from the model</code></pre>
<pre class="r"><code>pool_lr$RR_Model</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>pool_lr$multiparm</code></pre>
<pre><code>## $`Step 1 - removal - Smoking`
##                       p-values D1  F-statistic
## Gender               0.3573489015  0.847398097
## Smoking              0.9351090751  0.006629086
## Function             0.0007175925 11.496258992
## JobControl           0.7800813779  0.078093242
## JobDemands           0.9013696138  0.015377782
## SocialSupport        0.4191089815  0.653452178
## factor(Satisfaction) 0.5203572810  0.654738411
## 
## $`Step 2 - removal - JobDemands`
##                      p-values D1 F-statistic
## Gender               0.357284017  0.84762552
## Function             0.000701792 11.53368033
## JobControl           0.778937831  0.07892848
## JobDemands           0.902310755  0.01508410
## SocialSupport        0.420362557  0.64993997
## factor(Satisfaction) 0.510459302  0.67405488
## 
## $`Step 3 - removal - JobControl`
##                       p-values D1 F-statistic
## Gender               0.3394367824  0.91262498
## Function             0.0007054094 11.52921072
## JobControl           0.7836963849  0.07547789
## SocialSupport        0.4209104436  0.64835463
## factor(Satisfaction) 0.5142261855  0.66666092
## 
## $`Step 4 - removal - SocialSupport`
##                       p-values D1 F-statistic
## Gender               0.2927368751   1.1071226
## Function             0.0007980798  11.3418578
## SocialSupport        0.4448293996   0.5843689
## factor(Satisfaction) 0.5004930621   0.6937948
## 
## $`Step 5 - removal - Gender`
##                       p-values D1 F-statistic
## Gender               0.2661240274   1.2367531
## Function             0.0009425647  11.0294608
## factor(Satisfaction) 0.5239840847   0.6477149
## 
## $`Step 6 - removal - ended`
##                      p-values D1 F-statistic
## Function             0.000645971  11.7563951
## factor(Satisfaction) 0.567898285   0.5669431</code></pre>
<p>Back to <a href="#examples">Examples</a></p>
</div>
<div id="pooling-with-bs-and-forcing-dichotomous-and-categorical-variable-in-the-model" class="section level3">
<h3>Pooling with BS and forcing dichotomous and categorical variable in the model</h3>
<p>Pooling Logistic regression models over 5 imputed datasets with backward selection
using a p-value of 0.05 and forcing the dichotomous predictor “Smoking” and categorical
predictor “Satisfaction” in the models during backward selection with method D1.</p>
<pre class="r"><code>library(psfmi)
pool_lr &lt;- psfmi_lr(data=lbpmilr, nimp=5, impvar=&quot;Impnr&quot;, Outcome=&quot;Chronic&quot;,
    predictors=c(&quot;Gender&quot;, &quot;Smoking&quot;, &quot;Function&quot;, &quot;JobControl&quot;,
    &quot;JobDemands&quot;, &quot;SocialSupport&quot;), cat.predictors = &quot;Satisfaction&quot;, 
    keep.predictors = c(&quot;Satisfaction&quot;, &quot;Smoking&quot;),
    p.crit = 0.05, method=&quot;D1&quot;, direction=&quot;BW&quot;)</code></pre>
<pre><code>## Removed at Step 1 is - JobDemands</code></pre>
<pre><code>## Removed at Step 2 is - JobControl</code></pre>
<pre><code>## Removed at Step 3 is - SocialSupport</code></pre>
<pre><code>## Removed at Step 4 is - Gender</code></pre>
<pre><code>## 
## Selection correctly terminated, 
## No more variables removed from the model</code></pre>
<pre class="r"><code>pool_lr$RR_Model</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>pool_lr$multiparm</code></pre>
<pre><code>## $`Step 1 - removal - JobDemands`
##                       p-values D1  F-statistic
## Gender               0.3573489015  0.847398097
## Smoking              0.9351090751  0.006629086
## Function             0.0007175925 11.496258992
## JobControl           0.7800813779  0.078093242
## JobDemands           0.9013696138  0.015377782
## SocialSupport        0.4191089815  0.653452178
## factor(Satisfaction) 0.5203572810  0.654738411
## 
## $`Step 2 - removal - JobControl`
##                       p-values D1  F-statistic
## Gender               0.3394230225  0.912677425
## Smoking              0.9378443208  0.006080901
## Function             0.0007213489 11.491671726
## JobControl           0.7848416655  0.074661274
## SocialSupport        0.4196938335  0.651755427
## factor(Satisfaction) 0.5240836144  0.647564355
## 
## $`Step 3 - removal - SocialSupport`
##                       p-values D1  F-statistic
## Gender               0.2929839539  1.105991149
## Smoking              0.9370062682  0.006246338
## Function             0.0008162769 11.303991030
## SocialSupport        0.4433301611  0.588221771
## factor(Satisfaction) 0.5104735549  0.673933069
## 
## $`Step 4 - removal - Gender`
##                       p-values D1  F-statistic
## Gender               0.2662260828  1.236225982
## Smoking              0.9525907073  0.003534792
## Function             0.0009599856 10.998316481
## factor(Satisfaction) 0.5329101362  0.630726577
## 
## $`Step 5 - removal - ended`
##                       p-values D1  F-statistic
## Smoking              0.9526218671  0.003530147
## Function             0.0006606787 11.718193089
## factor(Satisfaction) 0.5762872019  0.552206139</code></pre>
<p>Back to <a href="#examples">Examples</a></p>
</div>
</div>
